# ğŸ“Š Customer Churn Prediction using Machine Learning

<p align="center">
  <img src="https://img.shields.io/badge/Model-CatBoost-blue" />
  <img src="https://img.shields.io/badge/Metric-PR--AUC-orange" />
  <img src="https://img.shields.io/badge/Problem-Customer%20Churn-red" />
  <img src="https://img.shields.io/badge/Status-Completed-success" />
</p>

---

## ğŸ§  Problem Statement
Customer churn directly impacts revenue and long-term growth.  
This project focuses on **identifying customers likely to churn** and **supporting business decisions** using a metric-driven machine learning approach.

---

## ğŸ¯ Project Objectives
- Handle **imbalanced churn data**
- Prioritize **recall for churners**
- Select an **optimal decision threshold**
- Compare baseline vs advanced models
- Translate ML outputs into **actionable business insights**

---

## ğŸ—‚ Dataset Overview
- **Dataset**: Telco Customer Churn (IBM)
- **Target Variable**: `Churn` (Yes / No)
- **Churn Rate**: ~23%
- **Challenge**: Highly imbalanced classes

---

## ğŸ“ Why PR-AUC instead of Accuracy?

Accuracy is misleading for imbalanced datasets.

**PR-AUC was chosen because:**
- Focuses on the **minority class (churners)**
- Captures the **precisionâ€“recall trade-off**
- Aligns with the **business cost of missing churners**

---

## ğŸ§ª Modeling Pipeline

```text
Data Cleaning
     â†“
EDA & Feature Understanding
     â†“
Baseline Model (Logistic Regression)
     â†“
CatBoost Classifier
     â†“
PR-AUC Evaluation
     â†“
Threshold Optimization
     â†“
Feature Importance & SHAP Analysis
     â†“
Business Insights
```
## ğŸ¤– Models Used

| Model | Purpose |
|------|--------|
| **Logistic Regression** | Baseline comparison |
| **CatBoost Classifier** | Final model (handles categorical features natively) |

### ğŸ”§ Techniques Applied
- Stratified K-Fold Cross-Validation  
- Class Weights for imbalance handling  
- Early Stopping to prevent overfitting  
- Probability-based evaluation  
- Business-driven threshold tuning  

---

## ğŸ“ˆ Model Evaluation

### ğŸ”¹ Precisionâ€“Recall Curve Analysis
- Compared **Logistic Regression vs CatBoost**
- CatBoost consistently maintained **higher precision at high recall**
- Demonstrated superior ranking ability on imbalanced churn data

### ğŸ”¹ Threshold Selection
- Selected **threshold = 0.38**
- Achieved approximately **90% recall** for churners
- Threshold treated as a **business decision**, not a fixed statistical rule

---
```text
IF churn_probability > 0.38:
    â†’ High-Risk Customer
    â†’ Apply targeted retention strategy
ELSE:
    â†’ Low-Risk Customer

```

## ğŸ” Feature Importance & SHAP Explainability

SHAP was used to explain **both global feature importance** and **individual churn predictions**, ensuring transparency and trust.

### ğŸ”‘ Key Churn Drivers Identified
- ğŸ“„ **Contract** â†’ Month-to-month contracts significantly increase churn  
- â³ **Tenure** â†’ New customers are more likely to churn  
- ğŸ’° **MonthlyCharges** â†’ Higher charges correlate with churn  
- ğŸ” **OnlineSecurity / TechSupport** â†’ Reduce churn risk  
- ğŸ“º **StreamingTV / OnlineBackup** â†’ Increase customer stickiness  

SHAP analysis enabled the model to explain **why a specific customer is predicted to churn**, making the solution suitable for real-world decision support.

<img width="1187" height="774" alt="image" src="https://github.com/user-attachments/assets/8f0c5a56-02d5-42cc-8e26-d63efde64d81" />
